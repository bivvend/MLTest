{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, target to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n",
      "\n",
      "Fold  0\n",
      "0:\ttest: 0.5364710\tbest: 0.5364710 (0)\ttotal: 130ms\tremaining: 4m 20s\n",
      "200:\ttest: 0.8776868\tbest: 0.8776868 (200)\ttotal: 22.6s\tremaining: 3m 21s\n",
      "400:\ttest: 0.8900528\tbest: 0.8900528 (400)\ttotal: 45.2s\tremaining: 3m\n",
      "600:\ttest: 0.8947133\tbest: 0.8947133 (600)\ttotal: 1m 7s\tremaining: 2m 36s\n",
      "800:\ttest: 0.8963380\tbest: 0.8963380 (800)\ttotal: 1m 29s\tremaining: 2m 13s\n",
      "1000:\ttest: 0.8966581\tbest: 0.8967353 (993)\ttotal: 1m 51s\tremaining: 1m 51s\n",
      "1200:\ttest: 0.8970510\tbest: 0.8970800 (1194)\ttotal: 2m 13s\tremaining: 1m 29s\n",
      "1400:\ttest: 0.8970907\tbest: 0.8972818 (1294)\ttotal: 2m 35s\tremaining: 1m 6s\n",
      "1600:\ttest: 0.8970987\tbest: 0.8972818 (1294)\ttotal: 2m 57s\tremaining: 44.2s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.8972817673\n",
      "bestIteration = 1294\n",
      "\n",
      "Shrink model to first 1295 iterations.\n",
      "  auc =  0.8972817673087907\n",
      "\n",
      "Fold  1\n",
      "0:\ttest: 0.5289212\tbest: 0.5289212 (0)\ttotal: 133ms\tremaining: 4m 26s\n",
      "200:\ttest: 0.8768427\tbest: 0.8768427 (200)\ttotal: 21.9s\tremaining: 3m 16s\n",
      "400:\ttest: 0.8903112\tbest: 0.8903112 (400)\ttotal: 44.2s\tremaining: 2m 56s\n",
      "600:\ttest: 0.8950757\tbest: 0.8950757 (600)\ttotal: 1m 6s\tremaining: 2m 34s\n",
      "800:\ttest: 0.8968726\tbest: 0.8968837 (799)\ttotal: 1m 28s\tremaining: 2m 12s\n",
      "1000:\ttest: 0.8981319\tbest: 0.8981920 (988)\ttotal: 1m 50s\tremaining: 1m 50s\n",
      "1200:\ttest: 0.8982728\tbest: 0.8984525 (1087)\ttotal: 2m 12s\tremaining: 1m 28s\n",
      "1400:\ttest: 0.8984491\tbest: 0.8985040 (1282)\ttotal: 2m 34s\tremaining: 1m 6s\n",
      "1600:\ttest: 0.8983771\tbest: 0.8985040 (1282)\ttotal: 2m 56s\tremaining: 43.9s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.8985039907\n",
      "bestIteration = 1282\n",
      "\n",
      "Shrink model to first 1283 iterations.\n",
      "  auc =  0.8985039907129079\n",
      "\n",
      "Fold  2\n",
      "0:\ttest: 0.5312630\tbest: 0.5312630 (0)\ttotal: 137ms\tremaining: 4m 33s\n",
      "200:\ttest: 0.8780973\tbest: 0.8780973 (200)\ttotal: 21.8s\tremaining: 3m 15s\n",
      "400:\ttest: 0.8911877\tbest: 0.8911877 (400)\ttotal: 44.2s\tremaining: 2m 56s\n",
      "600:\ttest: 0.8955378\tbest: 0.8955378 (600)\ttotal: 1m 6s\tremaining: 2m 34s\n",
      "800:\ttest: 0.8972996\tbest: 0.8972996 (800)\ttotal: 1m 28s\tremaining: 2m 12s\n",
      "1000:\ttest: 0.8981192\tbest: 0.8981260 (997)\ttotal: 1m 50s\tremaining: 1m 50s\n",
      "1200:\ttest: 0.8983562\tbest: 0.8984631 (1148)\ttotal: 2m 12s\tremaining: 1m 28s\n",
      "1400:\ttest: 0.8987201\tbest: 0.8987592 (1334)\ttotal: 2m 34s\tremaining: 1m 6s\n",
      "1600:\ttest: 0.8986722\tbest: 0.8988802 (1448)\ttotal: 2m 56s\tremaining: 43.9s\n",
      "1800:\ttest: 0.8988513\tbest: 0.8989023 (1685)\ttotal: 3m 17s\tremaining: 21.9s\n",
      "1999:\ttest: 0.8985871\tbest: 0.8989023 (1685)\ttotal: 3m 39s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8989023274\n",
      "bestIteration = 1685\n",
      "\n",
      "Shrink model to first 1686 iterations.\n",
      "  auc =  0.8989023274161883\n",
      "\n",
      "Fold  3\n",
      "0:\ttest: 0.5316047\tbest: 0.5316047 (0)\ttotal: 129ms\tremaining: 4m 17s\n",
      "200:\ttest: 0.8775641\tbest: 0.8775641 (200)\ttotal: 21.8s\tremaining: 3m 14s\n",
      "400:\ttest: 0.8904493\tbest: 0.8904493 (400)\ttotal: 43.9s\tremaining: 2m 55s\n",
      "600:\ttest: 0.8940454\tbest: 0.8940493 (598)\ttotal: 1m 5s\tremaining: 2m 33s\n",
      "800:\ttest: 0.8960377\tbest: 0.8960662 (790)\ttotal: 1m 28s\tremaining: 2m 11s\n",
      "1000:\ttest: 0.8969146\tbest: 0.8969222 (998)\ttotal: 1m 49s\tremaining: 1m 49s\n",
      "1200:\ttest: 0.8971256\tbest: 0.8971603 (1196)\ttotal: 2m 11s\tremaining: 1m 27s\n",
      "1400:\ttest: 0.8975068\tbest: 0.8975175 (1377)\ttotal: 2m 33s\tremaining: 1m 5s\n",
      "1600:\ttest: 0.8974374\tbest: 0.8975221 (1411)\ttotal: 2m 54s\tremaining: 43.6s\n",
      "1800:\ttest: 0.8973484\tbest: 0.8975221 (1411)\ttotal: 3m 16s\tremaining: 21.7s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.897522148\n",
      "bestIteration = 1411\n",
      "\n",
      "Shrink model to first 1412 iterations.\n",
      "  auc =  0.8975221480263429\n",
      "\n",
      "Fold  4\n",
      "0:\ttest: 0.5384318\tbest: 0.5384318 (0)\ttotal: 122ms\tremaining: 4m 3s\n",
      "200:\ttest: 0.8725962\tbest: 0.8725962 (200)\ttotal: 21.7s\tremaining: 3m 13s\n",
      "400:\ttest: 0.8862283\tbest: 0.8862283 (400)\ttotal: 43.9s\tremaining: 2m 55s\n",
      "600:\ttest: 0.8902241\tbest: 0.8902241 (600)\ttotal: 1m 6s\tremaining: 2m 33s\n",
      "800:\ttest: 0.8921141\tbest: 0.8921245 (795)\ttotal: 1m 28s\tremaining: 2m 12s\n",
      "1000:\ttest: 0.8933102\tbest: 0.8933813 (976)\ttotal: 1m 50s\tremaining: 1m 50s\n",
      "1200:\ttest: 0.8937525\tbest: 0.8937797 (1116)\ttotal: 2m 12s\tremaining: 1m 27s\n",
      "1400:\ttest: 0.8939765\tbest: 0.8940570 (1356)\ttotal: 2m 34s\tremaining: 1m 5s\n",
      "1600:\ttest: 0.8941945\tbest: 0.8943020 (1554)\ttotal: 2m 55s\tremaining: 43.8s\n",
      "1800:\ttest: 0.8943214\tbest: 0.8944736 (1746)\ttotal: 3m 17s\tremaining: 21.8s\n",
      "1999:\ttest: 0.8942072\tbest: 0.8944736 (1746)\ttotal: 3m 38s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8944736122\n",
      "bestIteration = 1746\n",
      "\n",
      "Shrink model to first 1747 iterations.\n",
      "  auc =  0.8944736121961853\n"
     ]
    }
   ],
   "source": [
    "#CatBoost\n",
    "\n",
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "idx = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = train_df['target']\n",
    "\n",
    "df_list = [train_df, test_df]\n",
    "new_df_list = []\n",
    "new_train_df = pd.DataFrame()\n",
    "new_train_df['target'] = train_df['target']\n",
    "new_train_df['ID_code'] = train_df['ID_code']\n",
    "new_test_df = pd.DataFrame()\n",
    "new_test_df['ID_code'] = test_df['ID_code']\n",
    "new_df_list = [new_train_df, new_test_df]\n",
    "for i in range(0, len(df_list)):        \n",
    "    for feat in idx:\n",
    "        mean = df_list[i].loc[:,feat].mean()\n",
    "        new_df_list[i][feat] = df_list[i][feat]\n",
    "#         new_df_list[i][\"mm_\" + feat] = np.round(df_list[i][feat] - mean , 2) \n",
    "#         if mean > 0:\n",
    "#             new_df_list[i][\"is_more_\" + feat] = np.where( df_list[i][feat] > mean, 10, -10 )\n",
    "#         if mean < 0: \n",
    "#             new_df_list[i][\"is_more_\" + feat] = np.where( df_list[i][feat] < mean, 10, -10 )\n",
    "            \n",
    "features = [c for c in new_train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = new_train_df['target']\n",
    "\n",
    "N_FOLDS = 5.0\n",
    "\n",
    "model = CatBoostClassifier(loss_function=\"Logloss\", eval_metric=\"AUC\", iterations=2000, early_stopping_rounds= 500, l2_leaf_reg= 9, learning_rate= 0.1)\n",
    "#model = CatBoostClassifier(eval_metric=\"AUC\", depth=10, iterations= 1500, l2_leaf_reg= 9, learning_rate= 0.15)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=int(N_FOLDS), random_state=2019, shuffle=True)\n",
    "\n",
    "y_valid_pred = 0 * target\n",
    "y_test_pred = 0\n",
    "y_train_pred = 0 #storing results for ensemble\n",
    "\n",
    "new_train_df.info()\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(new_train_df)):\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    X_train, X_valid = new_train_df[features].iloc[train_index,:], new_train_df[features].iloc[valid_index,:]\n",
    "    _train = Pool(X_train, label=y_train)\n",
    "    _valid = Pool(X_valid, label=y_valid)\n",
    "    print( \"\\nFold \", idx)\n",
    "    fit_model = model.fit(_train,\n",
    "                          eval_set=_valid,\n",
    "                          use_best_model=True,\n",
    "                          verbose=200\n",
    "                         )\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
    "    print( \"  auc = \", roc_auc_score(y_valid, pred) )\n",
    "    y_valid_pred.iloc[valid_index] = pred\n",
    "    y_test_pred += fit_model.predict_proba(new_test_df[features])[:,1]\n",
    "    y_train_pred += fit_model.predict_proba(new_train_df[features])[:,1]\n",
    "y_test_pred /= N_FOLDS\n",
    "y_train_pred /= N_FOLDS\n",
    "\n",
    "#save an intermediate submission\n",
    "sub_df1 = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\n",
    "sub_df1[\"target\"] = y_test_pred\n",
    "sub_df1.to_csv(\"submission_catboost.csv\", index=False)\n",
    "\n",
    "ens_cat_df = pd.DataFrame({\"ID_code\":train_df[\"ID_code\"].values})\n",
    "ens_cat_df[\"output\"] = y_train_pred\n",
    "ens_cat_df.to_csv(\"../input/catboost_output.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.905752\tvalid_1's auc: 0.885235\n",
      "[2000]\ttraining's auc: 0.916553\tvalid_1's auc: 0.891313\n",
      "[3000]\ttraining's auc: 0.925128\tvalid_1's auc: 0.8953\n",
      "[4000]\ttraining's auc: 0.931935\tvalid_1's auc: 0.897273\n",
      "[5000]\ttraining's auc: 0.937554\tvalid_1's auc: 0.898575\n",
      "[6000]\ttraining's auc: 0.942476\tvalid_1's auc: 0.89927\n",
      "[7000]\ttraining's auc: 0.946842\tvalid_1's auc: 0.899761\n",
      "Early stopping, best iteration is:\n",
      "[6992]\ttraining's auc: 0.946805\tvalid_1's auc: 0.899777\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-7a9ddd1e4598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mtrn_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrn_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0moof\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meval_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkeep_training_booster\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_from_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbooster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mmodel_from_string\u001b[1;34m(self, model_str, verbose)\u001b[0m\n\u001b[0;32m   2052\u001b[0m             \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2053\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_num_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2054\u001b[1;33m             ctypes.byref(self.handle)))\n\u001b[0m\u001b[0;32m   2055\u001b[0m         \u001b[0mout_num_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2056\u001b[0m         _safe_call(_LIB.LGBM_BoosterGetNumClasses(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#####LightGBM\n",
    "param = {\n",
    "            'num_leaves': 15, #was 10\n",
    "            'max_bin': 119,\n",
    "            'min_data_in_leaf': 11,\n",
    "            'learning_rate': 0.01,\n",
    "            'min_sum_hessian_in_leaf': 0.00245,\n",
    "            'bagging_fraction': 1.0, \n",
    "            'bagging_freq': 5, \n",
    "            'feature_fraction': 0.05,\n",
    "            'lambda_l1': 4.972,\n",
    "            'lambda_l2': 50.0,   #30 #2.276,\n",
    "            'min_gain_to_split': 0.65,\n",
    "            'max_depth': 20, #17 #was 14\n",
    "            'save_binary': True,\n",
    "            'seed': 1337,\n",
    "            'feature_fraction_seed': 1337,\n",
    "            'bagging_seed': 1337,\n",
    "            'drop_seed': 1337,\n",
    "            'data_random_seed': 1337,\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'verbose': 1,\n",
    "            'metric': 'auc',\n",
    "            'is_unbalance': True,\n",
    "            'boost_from_average': True, #was false\n",
    "        }\n",
    "num_round = 15000\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "train_preds = np.zeros(len(train_df))\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 200)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    train_preds += clf.predict(train_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "\n",
    "sub = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "sub_lgb = pd.DataFrame({\"ID_code\": train_df.ID_code.values})\n",
    "sub[\"target\"] = predictions\n",
    "sub_lgb[\"output\"] = train_preds\n",
    "sub.to_csv(\"submission_lgbm.csv\", index=False)\n",
    "sub_lgb.to_csv(\"../input/lgbm_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,577\n",
      "Trainable params: 8,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##NN Ensemble\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(2,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "N_FOLDS = 5.0\n",
    "\n",
    "kf = KFold(n_splits=int(N_FOLDS), random_state=2019, shuffle=True)\n",
    "\n",
    "#Load previous data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "160000/160000 [==============================] - 2s 12us/step - loss: 0.1933 - acc: 0.9388 - val_loss: 0.1452 - val_acc: 0.9475\n",
      "Epoch 2/5\n",
      "160000/160000 [==============================] - 2s 9us/step - loss: 0.1427 - acc: 0.9478 - val_loss: 0.1464 - val_acc: 0.9456\n",
      "Epoch 3/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1397 - acc: 0.9492 - val_loss: 0.1345 - val_acc: 0.9520\n",
      "Epoch 4/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1364 - acc: 0.9519 - val_loss: 0.1302 - val_acc: 0.9544\n",
      "Epoch 5/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1332 - acc: 0.9544 - val_loss: 0.1266 - val_acc: 0.9587\n",
      "(40000, 1)\n",
      "  auc =  0.9586908932205548\n",
      "(200000,)\n",
      "Fold 1\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1312 - acc: 0.9563 - val_loss: 0.1217 - val_acc: 0.9603\n",
      "Epoch 2/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1292 - acc: 0.9573 - val_loss: 0.1195 - val_acc: 0.9622\n",
      "Epoch 3/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1275 - acc: 0.9581 - val_loss: 0.1183 - val_acc: 0.9625\n",
      "Epoch 4/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1262 - acc: 0.9583 - val_loss: 0.1173 - val_acc: 0.9626\n",
      "Epoch 5/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1255 - acc: 0.9589 - val_loss: 0.1160 - val_acc: 0.9635\n",
      "(40000, 1)\n",
      "  auc =  0.9610908166373133\n",
      "(200000,)\n",
      "Fold 2\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1225 - acc: 0.9600 - val_loss: 0.1289 - val_acc: 0.9578\n",
      "Epoch 2/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1219 - acc: 0.9604 - val_loss: 0.1243 - val_acc: 0.9589\n",
      "Epoch 3/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1210 - acc: 0.9608 - val_loss: 0.1238 - val_acc: 0.9589\n",
      "Epoch 4/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1209 - acc: 0.9606 - val_loss: 0.1370 - val_acc: 0.9537\n",
      "Epoch 5/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1199 - acc: 0.9608 - val_loss: 0.1228 - val_acc: 0.9591\n",
      "(40000, 1)\n",
      "  auc =  0.9585365632822833\n",
      "(200000,)\n",
      "Fold 3\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1211 - acc: 0.9602 - val_loss: 0.1232 - val_acc: 0.9583\n",
      "Epoch 2/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1205 - acc: 0.9603 - val_loss: 0.1239 - val_acc: 0.9593\n",
      "Epoch 3/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1202 - acc: 0.9602 - val_loss: 0.1201 - val_acc: 0.9613\n",
      "Epoch 4/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1197 - acc: 0.9604 - val_loss: 0.1179 - val_acc: 0.9612\n",
      "Epoch 5/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1195 - acc: 0.9606 - val_loss: 0.1162 - val_acc: 0.9621\n",
      "(40000, 1)\n",
      "  auc =  0.9621670670706727\n",
      "(200000,)\n",
      "Fold 4\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1169 - acc: 0.9616 - val_loss: 0.1247 - val_acc: 0.9578\n",
      "Epoch 2/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1171 - acc: 0.9615 - val_loss: 0.1235 - val_acc: 0.9585\n",
      "Epoch 3/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1165 - acc: 0.9618 - val_loss: 0.1248 - val_acc: 0.9576\n",
      "Epoch 4/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1164 - acc: 0.9617 - val_loss: 0.1236 - val_acc: 0.9588\n",
      "Epoch 5/5\n",
      "160000/160000 [==============================] - 1s 9us/step - loss: 0.1162 - acc: 0.9618 - val_loss: 0.1230 - val_acc: 0.9580\n",
      "(40000, 1)\n",
      "  auc =  0.9592299448806322\n",
      "(200000,)\n"
     ]
    }
   ],
   "source": [
    "catb_df = pd.read_csv(\"../input/catboost_output.csv\")\n",
    "lgbm_df = pd.read_csv(\"../input/lgbm_output.csv\")\n",
    "\n",
    "submission_catb_df = pd.read_csv(\"submission_catboost.csv\")\n",
    "submission_lgbm_df = pd.read_csv(\"submission_lgbm.csv\")\n",
    "\n",
    "combined_df = pd.DataFrame({\"ID_code\": catb_df.ID_code.values})\n",
    "combined_df['cat_out'] = catb_df['output']\n",
    "combined_df['lgbm_out'] = lgbm_df['output']\n",
    "combined_df['target'] = train_df['target']\n",
    "\n",
    "combined_test_df = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "combined_test_df['cat_out'] = submission_catb_df['target']\n",
    "combined_test_df['lgbm_out'] = submission_lgbm_df['target']\n",
    "\n",
    "\n",
    "combined_df.to_csv('../input/combined.csv')\n",
    "\n",
    "#idx = [c for c in combined_df.columns if c not in ['ID_code', 'target']]\n",
    "features = [c for c in combined_df.columns if c not in ['ID_code', 'target']]\n",
    "target = combined_df['target']\n",
    "\n",
    "y_test_pred = np.zeros(len(test_df))\n",
    "    \n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(combined_df)):\n",
    "    print(\"Fold {}\".format(idx))\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    X_train, X_valid = combined_df[features].iloc[train_index,:], combined_df[features].iloc[valid_index,:]\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size = 512, validation_data =(X_valid, y_valid))\n",
    "    pred = model.predict_proba(X_valid)\n",
    "    print(pred.shape)\n",
    "    print( \"  auc = \", roc_auc_score(y_valid, pred) )\n",
    "    y_test_pred += model.predict_proba(combined_test_df[features])[:,0]\n",
    "    print(y_test_pred.shape)\n",
    "\n",
    "sub_df1 = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\n",
    "sub_df1[\"target\"] = y_test_pred / N_FOLDS\n",
    "sub_df1.to_csv(\"submission_nn.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
