{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENSEMBLE TEST 2\n",
    "##NN Ensemble \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(3,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "N_FOLDS = 5.0\n",
    "\n",
    "kf = KFold(n_splits=int(N_FOLDS), random_state=2019, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load previous data\n",
    "\n",
    "catb_df = pd.read_csv(\"../input/catboost_output.csv\")\n",
    "lgbm_df = pd.read_csv(\"../input/output_test_lgbm_base3.csv\")\n",
    "nn_df = pd.read_csv(\"../input/full_nn_equal_output.csv\")\n",
    "\n",
    "submission_catb_df = pd.read_csv(\"submission_catboost.csv\")\n",
    "submission_lgbm_df = pd.read_csv(\"submission_lgbm_base3.csv\")\n",
    "submission_full_nn_df = pd.read_csv(\"submission_full_nn_equal.csv\")\n",
    "\n",
    "combined_df = pd.DataFrame({\"ID_code\": catb_df.ID_code.values})\n",
    "combined_df['cat_out'] = catb_df['output']\n",
    "combined_df['lgbm_out'] = lgbm_df['output']\n",
    "combined_df['full_nn_out'] = nn_df['output']\n",
    "combined_df['target1'] = train_df['target']\n",
    "combined_df['target0'] = 1 - train_df['target']\n",
    "\n",
    "#drop 90% of 0 scores to make balanced input for NN\n",
    "#combined_df = combined_df.drop(combined_df[combined_df['target0'] > 0.9].sample(frac=0.1).index)\n",
    "zero_subset_df = combined_df[combined_df['target0'] > 0.9].sample(frac = 0.1)\n",
    "ones_subset_df = combined_df[combined_df['target1'] > 0.9]\n",
    "\n",
    "frames = [zero_subset_df, ones_subset_df]\n",
    "\n",
    "combined_df = pd.concat(frames)\n",
    "combined_df = shuffle(combined_df)\n",
    "\n",
    "combined_test_df = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "combined_test_df['cat_out'] = submission_catb_df['target']\n",
    "combined_test_df['lgbm_out'] = submission_lgbm_df['target']\n",
    "combined_test_df['full_nn_out'] = submission_full_nn_df['target']\n",
    "\n",
    "zero_subset_df.to_csv('../input/zeros_sample.csv')\n",
    "ones_subset_df.to_csv('../input/ones_sample.csv')\n",
    "combined_df.to_csv('../input/combined.csv')\n",
    "\n",
    "#idx = [c for c in combined_df.columns if c not in ['ID_code', 'target']]\n",
    "features = [c for c in combined_df.columns if c not in ['ID_code', 'target', 'target1', 'target0']]\n",
    "target = combined_df.loc[:, ['target1', 'target0']]\n",
    "\n",
    "y_test_pred = np.zeros(len(test_df))\n",
    "    \n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(combined_df)):\n",
    "    print(\"Fold {}\".format(idx))\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    X_train, X_valid = combined_df[features].iloc[train_index,:], combined_df[features].iloc[valid_index,:]\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size = 512, validation_data =(X_valid, y_valid))\n",
    "    pred = model.predict_proba(X_valid)\n",
    "    print(pred.shape)\n",
    "    print( \"  auc = \", roc_auc_score(y_valid, pred) )\n",
    "    y_test_pred += model.predict_proba(combined_test_df[features])[:,0]\n",
    "    print(y_test_pred.shape)\n",
    "\n",
    "#save base submission\n",
    "sub_df1 = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\n",
    "sub_df1[\"target\"] = y_test_pred / N_FOLDS\n",
    "sub_df1.to_csv(\"submission_nn_ensemble2.csv\", index=False)\n",
    "#make combined data set for comparison\n",
    "combined_test_df['nn_out'] = y_test_pred / N_FOLDS\n",
    "combined_test_df.to_csv(\"../input/combined_output_ensemble2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
