{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, target to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n",
      "\n",
      "Fold  0\n",
      "0:\ttest: 0.5364710\tbest: 0.5364710 (0)\ttotal: 199ms\tremaining: 6m 38s\n",
      "200:\ttest: 0.8776868\tbest: 0.8776868 (200)\ttotal: 23.2s\tremaining: 3m 28s\n",
      "400:\ttest: 0.8900528\tbest: 0.8900528 (400)\ttotal: 49.2s\tremaining: 3m 16s\n",
      "600:\ttest: 0.8947133\tbest: 0.8947133 (600)\ttotal: 1m 12s\tremaining: 2m 49s\n",
      "800:\ttest: 0.8963380\tbest: 0.8963380 (800)\ttotal: 1m 37s\tremaining: 2m 25s\n",
      "1000:\ttest: 0.8966581\tbest: 0.8967353 (993)\ttotal: 2m\tremaining: 2m\n",
      "1200:\ttest: 0.8970510\tbest: 0.8970800 (1194)\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "1400:\ttest: 0.8970907\tbest: 0.8972818 (1294)\ttotal: 2m 46s\tremaining: 1m 11s\n",
      "1600:\ttest: 0.8970987\tbest: 0.8972818 (1294)\ttotal: 3m 8s\tremaining: 47s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.8972817673\n",
      "bestIteration = 1294\n",
      "\n",
      "Shrink model to first 1295 iterations.\n",
      "  auc =  0.8972817673087907\n",
      "\n",
      "Fold  1\n",
      "0:\ttest: 0.5289212\tbest: 0.5289212 (0)\ttotal: 121ms\tremaining: 4m 1s\n",
      "200:\ttest: 0.8768427\tbest: 0.8768427 (200)\ttotal: 22.2s\tremaining: 3m 18s\n",
      "400:\ttest: 0.8903112\tbest: 0.8903112 (400)\ttotal: 45.1s\tremaining: 2m 59s\n",
      "600:\ttest: 0.8950757\tbest: 0.8950757 (600)\ttotal: 1m 7s\tremaining: 2m 37s\n",
      "800:\ttest: 0.8968726\tbest: 0.8968837 (799)\ttotal: 1m 30s\tremaining: 2m 15s\n",
      "1000:\ttest: 0.8981319\tbest: 0.8981920 (988)\ttotal: 1m 52s\tremaining: 1m 52s\n",
      "1200:\ttest: 0.8982728\tbest: 0.8984525 (1087)\ttotal: 2m 14s\tremaining: 1m 29s\n",
      "1400:\ttest: 0.8984491\tbest: 0.8985040 (1282)\ttotal: 2m 37s\tremaining: 1m 7s\n",
      "1600:\ttest: 0.8983771\tbest: 0.8985040 (1282)\ttotal: 2m 58s\tremaining: 44.6s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.8985039907\n",
      "bestIteration = 1282\n",
      "\n",
      "Shrink model to first 1283 iterations.\n",
      "  auc =  0.8985039907129079\n",
      "\n",
      "Fold  2\n",
      "0:\ttest: 0.5312630\tbest: 0.5312630 (0)\ttotal: 121ms\tremaining: 4m 1s\n",
      "200:\ttest: 0.8780973\tbest: 0.8780973 (200)\ttotal: 21.8s\tremaining: 3m 15s\n",
      "400:\ttest: 0.8911877\tbest: 0.8911877 (400)\ttotal: 44s\tremaining: 2m 55s\n",
      "600:\ttest: 0.8955378\tbest: 0.8955378 (600)\ttotal: 1m 6s\tremaining: 2m 34s\n",
      "800:\ttest: 0.8972996\tbest: 0.8972996 (800)\ttotal: 1m 29s\tremaining: 2m 13s\n",
      "1000:\ttest: 0.8981192\tbest: 0.8981260 (997)\ttotal: 1m 51s\tremaining: 1m 50s\n",
      "1200:\ttest: 0.8983562\tbest: 0.8984631 (1148)\ttotal: 2m 13s\tremaining: 1m 28s\n",
      "1400:\ttest: 0.8987201\tbest: 0.8987592 (1334)\ttotal: 2m 34s\tremaining: 1m 6s\n",
      "1600:\ttest: 0.8986722\tbest: 0.8988802 (1448)\ttotal: 2m 56s\tremaining: 43.9s\n",
      "1800:\ttest: 0.8988513\tbest: 0.8989023 (1685)\ttotal: 3m 17s\tremaining: 21.9s\n",
      "1999:\ttest: 0.8985871\tbest: 0.8989023 (1685)\ttotal: 3m 39s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8989023274\n",
      "bestIteration = 1685\n",
      "\n",
      "Shrink model to first 1686 iterations.\n",
      "  auc =  0.8989023274161883\n",
      "\n",
      "Fold  3\n",
      "0:\ttest: 0.5316047\tbest: 0.5316047 (0)\ttotal: 119ms\tremaining: 3m 58s\n",
      "200:\ttest: 0.8775641\tbest: 0.8775641 (200)\ttotal: 21.8s\tremaining: 3m 15s\n",
      "400:\ttest: 0.8904493\tbest: 0.8904493 (400)\ttotal: 44.1s\tremaining: 2m 56s\n",
      "600:\ttest: 0.8940454\tbest: 0.8940493 (598)\ttotal: 1m 6s\tremaining: 2m 34s\n",
      "800:\ttest: 0.8960377\tbest: 0.8960662 (790)\ttotal: 1m 29s\tremaining: 2m 14s\n",
      "1000:\ttest: 0.8969146\tbest: 0.8969222 (998)\ttotal: 1m 51s\tremaining: 1m 51s\n",
      "1200:\ttest: 0.8971256\tbest: 0.8971603 (1196)\ttotal: 2m 13s\tremaining: 1m 29s\n",
      "1400:\ttest: 0.8975068\tbest: 0.8975175 (1377)\ttotal: 2m 35s\tremaining: 1m 6s\n",
      "1600:\ttest: 0.8974374\tbest: 0.8975221 (1411)\ttotal: 2m 57s\tremaining: 44.3s\n",
      "1800:\ttest: 0.8973484\tbest: 0.8975221 (1411)\ttotal: 3m 18s\tremaining: 22s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.897522148\n",
      "bestIteration = 1411\n",
      "\n",
      "Shrink model to first 1412 iterations.\n",
      "  auc =  0.8975221480263429\n",
      "\n",
      "Fold  4\n",
      "0:\ttest: 0.5384318\tbest: 0.5384318 (0)\ttotal: 127ms\tremaining: 4m 12s\n",
      "200:\ttest: 0.8725962\tbest: 0.8725962 (200)\ttotal: 22.1s\tremaining: 3m 18s\n",
      "400:\ttest: 0.8862283\tbest: 0.8862283 (400)\ttotal: 44.5s\tremaining: 2m 57s\n",
      "600:\ttest: 0.8902241\tbest: 0.8902241 (600)\ttotal: 1m 7s\tremaining: 2m 36s\n",
      "800:\ttest: 0.8921141\tbest: 0.8921245 (795)\ttotal: 1m 29s\tremaining: 2m 14s\n",
      "1000:\ttest: 0.8933102\tbest: 0.8933813 (976)\ttotal: 1m 51s\tremaining: 1m 51s\n",
      "1200:\ttest: 0.8937525\tbest: 0.8937797 (1116)\ttotal: 2m 13s\tremaining: 1m 29s\n",
      "1400:\ttest: 0.8939765\tbest: 0.8940570 (1356)\ttotal: 2m 35s\tremaining: 1m 6s\n",
      "1600:\ttest: 0.8941945\tbest: 0.8943020 (1554)\ttotal: 2m 57s\tremaining: 44.2s\n",
      "1800:\ttest: 0.8943214\tbest: 0.8944736 (1746)\ttotal: 3m 19s\tremaining: 22s\n",
      "1999:\ttest: 0.8942072\tbest: 0.8944736 (1746)\ttotal: 3m 40s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8944736122\n",
      "bestIteration = 1746\n",
      "\n",
      "Shrink model to first 1747 iterations.\n",
      "  auc =  0.8944736121961853\n"
     ]
    }
   ],
   "source": [
    "#CatBoost\n",
    "\n",
    "idx = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = train_df['target']\n",
    "\n",
    "df_list = [train_df, test_df]\n",
    "new_df_list = []\n",
    "new_train_df = pd.DataFrame()\n",
    "new_train_df['target'] = train_df['target']\n",
    "new_train_df['ID_code'] = train_df['ID_code']\n",
    "new_test_df = pd.DataFrame()\n",
    "new_test_df['ID_code'] = test_df['ID_code']\n",
    "new_df_list = [new_train_df, new_test_df]\n",
    "for i in range(0, len(df_list)):        \n",
    "    for feat in idx:\n",
    "        mean = df_list[i].loc[:,feat].mean()\n",
    "        new_df_list[i][feat] = df_list[i][feat]\n",
    "#         new_df_list[i][\"mm_\" + feat] = np.round(df_list[i][feat] - mean , 2) \n",
    "#         if mean > 0:\n",
    "#             new_df_list[i][\"is_more_\" + feat] = np.where( df_list[i][feat] > mean, 10, -10 )\n",
    "#         if mean < 0: \n",
    "#             new_df_list[i][\"is_more_\" + feat] = np.where( df_list[i][feat] < mean, 10, -10 )\n",
    "            \n",
    "features = [c for c in new_train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = new_train_df['target']\n",
    "\n",
    "N_FOLDS = 5.0\n",
    "\n",
    "model = CatBoostClassifier(loss_function=\"Logloss\", eval_metric=\"AUC\", iterations=2000, early_stopping_rounds= 500, l2_leaf_reg= 9, learning_rate= 0.1)\n",
    "#model = CatBoostClassifier(eval_metric=\"AUC\", depth=10, iterations= 1500, l2_leaf_reg= 9, learning_rate= 0.15)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=int(N_FOLDS), random_state=2019, shuffle=True)\n",
    "\n",
    "y_valid_pred = 0 * target\n",
    "y_test_pred = 0\n",
    "y_train_pred = 0 #storing results for ensemble\n",
    "\n",
    "new_train_df.info()\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(new_train_df)):\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    X_train, X_valid = new_train_df[features].iloc[train_index,:], new_train_df[features].iloc[valid_index,:]\n",
    "    _train = Pool(X_train, label=y_train)\n",
    "    _valid = Pool(X_valid, label=y_valid)\n",
    "    print( \"\\nFold \", idx)\n",
    "    fit_model = model.fit(_train,\n",
    "                          eval_set=_valid,\n",
    "                          use_best_model=True,\n",
    "                          verbose=200\n",
    "                         )\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
    "    print( \"  auc = \", roc_auc_score(y_valid, pred) )\n",
    "    y_valid_pred.iloc[valid_index] = pred\n",
    "    y_test_pred += fit_model.predict_proba(new_test_df[features])[:,1]\n",
    "    y_train_pred += fit_model.predict_proba(new_train_df[features])[:,1]\n",
    "y_test_pred /= N_FOLDS\n",
    "y_train_pred /= N_FOLDS\n",
    "\n",
    "#save an intermediate submission\n",
    "sub_df1 = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\n",
    "sub_df1[\"target\"] = y_test_pred\n",
    "sub_df1.to_csv(\"submission_catboost.csv\", index=False)\n",
    "\n",
    "ens_cat_df = pd.DataFrame({\"ID_code\":train_df[\"ID_code\"].values})\n",
    "ens_cat_df[\"output\"] = y_train_pred\n",
    "ens_cat_df.to_csv(\"../input/catboost_output.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.905752\tvalid_1's auc: 0.885235\n",
      "[2000]\ttraining's auc: 0.916553\tvalid_1's auc: 0.891313\n",
      "[3000]\ttraining's auc: 0.925128\tvalid_1's auc: 0.8953\n",
      "[4000]\ttraining's auc: 0.931935\tvalid_1's auc: 0.897273\n",
      "[5000]\ttraining's auc: 0.937554\tvalid_1's auc: 0.898575\n",
      "[6000]\ttraining's auc: 0.942476\tvalid_1's auc: 0.89927\n",
      "[7000]\ttraining's auc: 0.946842\tvalid_1's auc: 0.899761\n",
      "Early stopping, best iteration is:\n",
      "[6992]\ttraining's auc: 0.946805\tvalid_1's auc: 0.899777\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.905963\tvalid_1's auc: 0.881145\n",
      "[2000]\ttraining's auc: 0.916829\tvalid_1's auc: 0.887732\n",
      "[3000]\ttraining's auc: 0.925329\tvalid_1's auc: 0.891503\n",
      "[4000]\ttraining's auc: 0.93206\tvalid_1's auc: 0.894145\n",
      "[5000]\ttraining's auc: 0.937718\tvalid_1's auc: 0.895683\n",
      "[6000]\ttraining's auc: 0.942712\tvalid_1's auc: 0.896609\n",
      "[7000]\ttraining's auc: 0.947081\tvalid_1's auc: 0.897234\n",
      "[8000]\ttraining's auc: 0.951157\tvalid_1's auc: 0.89754\n",
      "[9000]\ttraining's auc: 0.954874\tvalid_1's auc: 0.897688\n",
      "Early stopping, best iteration is:\n",
      "[9017]\ttraining's auc: 0.954935\tvalid_1's auc: 0.897699\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.905403\tvalid_1's auc: 0.887001\n",
      "[2000]\ttraining's auc: 0.916312\tvalid_1's auc: 0.892169\n",
      "[3000]\ttraining's auc: 0.924843\tvalid_1's auc: 0.895419\n",
      "[4000]\ttraining's auc: 0.931659\tvalid_1's auc: 0.897867\n",
      "[5000]\ttraining's auc: 0.937314\tvalid_1's auc: 0.899189\n",
      "[6000]\ttraining's auc: 0.942346\tvalid_1's auc: 0.900179\n",
      "[7000]\ttraining's auc: 0.946774\tvalid_1's auc: 0.90073\n",
      "[8000]\ttraining's auc: 0.95085\tvalid_1's auc: 0.90107\n",
      "Early stopping, best iteration is:\n",
      "[8702]\ttraining's auc: 0.953534\tvalid_1's auc: 0.901179\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.906532\tvalid_1's auc: 0.881533\n",
      "[2000]\ttraining's auc: 0.91727\tvalid_1's auc: 0.886858\n",
      "[3000]\ttraining's auc: 0.925981\tvalid_1's auc: 0.890518\n",
      "[4000]\ttraining's auc: 0.932827\tvalid_1's auc: 0.892468\n",
      "[5000]\ttraining's auc: 0.93856\tvalid_1's auc: 0.893741\n",
      "[6000]\ttraining's auc: 0.943569\tvalid_1's auc: 0.894436\n",
      "[7000]\ttraining's auc: 0.947955\tvalid_1's auc: 0.89488\n",
      "Early stopping, best iteration is:\n",
      "[7214]\ttraining's auc: 0.948848\tvalid_1's auc: 0.894964\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.906\tvalid_1's auc: 0.882141\n",
      "[2000]\ttraining's auc: 0.916757\tvalid_1's auc: 0.888237\n",
      "[3000]\ttraining's auc: 0.925329\tvalid_1's auc: 0.892066\n",
      "[4000]\ttraining's auc: 0.932098\tvalid_1's auc: 0.894368\n",
      "[5000]\ttraining's auc: 0.937749\tvalid_1's auc: 0.895907\n",
      "[6000]\ttraining's auc: 0.942758\tvalid_1's auc: 0.896864\n",
      "[7000]\ttraining's auc: 0.947162\tvalid_1's auc: 0.897499\n",
      "[8000]\ttraining's auc: 0.951245\tvalid_1's auc: 0.8978\n",
      "[9000]\ttraining's auc: 0.955009\tvalid_1's auc: 0.898007\n",
      "Early stopping, best iteration is:\n",
      "[9345]\ttraining's auc: 0.956226\tvalid_1's auc: 0.898069\n",
      "CV score: 0.89823 \n"
     ]
    }
   ],
   "source": [
    "#####LightGBM\n",
    "param = {\n",
    "            'num_leaves': 15, #was 10\n",
    "            'max_bin': 119,\n",
    "            'min_data_in_leaf': 11,\n",
    "            'learning_rate': 0.01,\n",
    "            'min_sum_hessian_in_leaf': 0.00245,\n",
    "            'bagging_fraction': 1.0, \n",
    "            'bagging_freq': 5, \n",
    "            'feature_fraction': 0.05,\n",
    "            'lambda_l1': 4.972,\n",
    "            'lambda_l2': 50.0,   #30 #2.276,\n",
    "            'min_gain_to_split': 0.65,\n",
    "            'max_depth': 20, #17 #was 14\n",
    "            'save_binary': True,\n",
    "            'seed': 1337,\n",
    "            'feature_fraction_seed': 1337,\n",
    "            'bagging_seed': 1337,\n",
    "            'drop_seed': 1337,\n",
    "            'data_random_seed': 1337,\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'verbose': 1,\n",
    "            'metric': 'auc',\n",
    "            'is_unbalance': True,\n",
    "            'boost_from_average': True, #was false\n",
    "        }\n",
    "num_round = 15000\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "train_preds = np.zeros(len(train_df))\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 200)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    train_preds += clf.predict(train_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "\n",
    "sub = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "sub_lgb = pd.DataFrame({\"ID_code\": train_df.ID_code.values})\n",
    "sub[\"target\"] = predictions\n",
    "sub_lgb[\"output\"] = train_preds\n",
    "sub.to_csv(\"submission_lgbm.csv\", index=False)\n",
    "sub_lgb.to_csv(\"../input/lgbm_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NN Fitting\n",
    "from keras.layers import (Flatten, Conv1D, Conv2D, Input, Dense, Dropout, BatchNormalization,\n",
    "                          concatenate, GaussianNoise, Reshape, TimeDistributed, LeakyReLU, PReLU, Embedding)\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from pathlib import Path\n",
    "from keras.callbacks import Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-1e443f73d008>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#kf = KFold(n_splits=int(N_FOLDS), random_state=2019, shuffle=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mcvlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12345786\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    329\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_BaseKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m         \u001b[0mtest_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    634\u001b[0m             raise ValueError(\n\u001b[0;32m    635\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[1;32m--> 636\u001b[1;33m                     allowed_target_types, type_of_target_y))\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead."
     ]
    }
   ],
   "source": [
    "feats = [\"var_{}\".format(i) for i in range(200)]\n",
    "targets2 = [\"target{}\".format(i), for i in range(0,2)]\n",
    "\n",
    "split_tar_df = train_df.copy(deep=True)\n",
    "split_tar_df['target1'] = train_df['target']\n",
    "split_tar_df['target0'] = 1 - train_df['target']\n",
    "\n",
    "X = train_df[feats]\n",
    "X_test = test_df[feats]\n",
    "\n",
    "y = split_tar_df[targets2]\n",
    "\n",
    "#N_FOLDS = 5.0\n",
    "\n",
    "#kf = KFold(n_splits=int(N_FOLDS), random_state=2019, shuffle=True)\n",
    "\n",
    "cvlist = list(StratifiedKFold(5, random_state=12345786).split(X, y))\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_sc = scaler.fit_transform(X)\n",
    "X_test_sc = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROC_AUC(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        self.X_val, self.y_val = validation_data\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(\"ROC AUC for this fold is \", roc_auc_score(self.y_val, self.model.predict(X_val)))\n",
    "        \n",
    "class NNv1(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,\n",
    "                 inp_shape=200,\n",
    "                 gaussian_noise=0.01,\n",
    "                 dense1_dim=32,\n",
    "                 dense2_dim=32,\n",
    "                 dense1_kwargs=None,\n",
    "                 dense2_kwargs=None,\n",
    "                 classifier_kwargs=None,\n",
    "                 optimizer=SGD,\n",
    "                 opt_kwargs=None,\n",
    "                 ):\n",
    "        self.inp_shape = inp_shape\n",
    "        self.gaussian_noise = gaussian_noise\n",
    "        self.dense1_dim = dense1_dim\n",
    "        self.dense2_dim = dense2_dim\n",
    "        self.dense1_kwargs = dense1_kwargs\n",
    "        self.dense2_kwargs = dense2_kwargs\n",
    "        self.classifier_kwargs = classifier_kwargs\n",
    "        self.optimizer = optimizer\n",
    "        self.opt_kwargs = opt_kwargs\n",
    "        self._default_initiaization()\n",
    "\n",
    "    def _default_initiaization(self):\n",
    "        if self.dense1_kwargs is None:\n",
    "            self.dense1_kwargs = {\"kernel_initializer\": \"glorot_uniform\"}\n",
    "        if self.dense2_kwargs is None:\n",
    "            self.dense2_kwargs = {\"kernel_initializer\": \"he_uniform\"}\n",
    "        if self.classifier_kwargs is None:\n",
    "            self.classifier_kwargs = {\"kernel_initializer\": \"he_uniform\"}\n",
    "        if self.opt_kwargs is None:\n",
    "            self.opt_kwargs = {}\n",
    "\n",
    "    def _build_model(self):\n",
    "        inp = Input(shape=(self.inp_shape,))\n",
    "        # x = GaussianNoise(self.gaussian_noise)(inp)\n",
    "        x = Reshape((self.inp_shape, 1))(inp)\n",
    "        d1 = Dense(self.dense1_dim, activation='tanh',)(x)\n",
    "        #d1 = TimeDistributed(Dropout(0.2))(d1)\n",
    "        d2 = Dense(self.dense1_dim, activation='relu',)(x)\n",
    "        #d2 = PReLU()(d2)\n",
    "        #d2 = TimeDistributed(Dropout(0.2))(d2)\n",
    "        x = concatenate([d1, d2])\n",
    "        x = Flatten()(x)\n",
    "        out = Dense(1, activation='sigmoid', **self.classifier_kwargs)(x)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=out)\n",
    "        opt = self.optimizer(**self.opt_kwargs)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y, *args, **kwargs):\n",
    "        self.model = self._build_model()\n",
    "        print(self.model.summary())\n",
    "        self.model.fit(X, y, *args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None, weight_path=None, **kwargs):\n",
    "        if self.model:\n",
    "            if weight_path is not None:\n",
    "                self.model.load_weights(weight_path)\n",
    "            y_hat = self.model.predict_proba(X, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(\"Model not fit yet\")\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 200, 1)       0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 200, 32)      64          reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 200, 32)      64          reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 200, 64)      0           dense_43[0][0]                   \n",
      "                                                                 dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 12800)        0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 1)            12801       flatten_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 12,929\n",
      "Trainable params: 12,929\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_45 to have shape (1,) but got array with shape (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-80793c63a98e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_sc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mROC_AUC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mval_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0my_preds_nn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-9d0024ffd58a>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, *args, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_45 to have shape (1,) but got array with shape (2,)"
     ]
    }
   ],
   "source": [
    "model = NNv1(opt_kwargs = {\"lr\": 0.01, \"momentum\": 0.9, \"nesterov\": True, \"clipnorm\": 1})\n",
    "y_preds_nn = np.zeros((len(y)))\n",
    "\n",
    "n = 0\n",
    "#for idx, (tr_idx, val_idx) in enumerate(kf.split(X_sc)):    \n",
    "for tr_idx, val_idx in cvlist:\n",
    "    print(\"Fold {}\".format(n))\n",
    "    n += 1\n",
    "    X_dev, y_dev = X_sc[tr_idx], y.iloc[tr_idx]\n",
    "    X_val, y_val = X_sc[val_idx], y.iloc[val_idx]\n",
    "    roc_auc = ROC_AUC((X_val, y_val))    \n",
    "    model.fit(X_dev, y_dev, validation_data=(X_val, y_val), epochs=20, batch_size=256, verbose=0, callbacks=[roc_auc])\n",
    "    val_preds = model.predict(X_val, batch_size=5000)\n",
    "    y_preds_nn[val_idx] = val_preds.flatten()\n",
    "    \n",
    "sub = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "output_df = pd.DataFrame({\"ID_code\": train_df.ID_code.values})\n",
    "y_test_preds = model.predict(X_test_sc, batch_size = 5000)\n",
    "y_train_preds = model.predict(X_sc, batch_size = 5000)\n",
    "sub['target'] = y_test_preds.flatten()\n",
    "output_df['output'] = y_train_preds.flatten()\n",
    "sub.to_csv('submission_full_nn.csv', index=False)\n",
    "output_df.to_csv('../input/full_nn_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 84,034\n",
      "Trainable params: 84,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##NN Ensemble \n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(3,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "N_FOLDS = 5.0\n",
    "\n",
    "kf = KFold(n_splits=int(N_FOLDS), random_state=2019, shuffle=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Train on 30470 samples, validate on 7618 samples\n",
      "Epoch 1/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1608 - acc: 0.9363 - val_loss: 0.1513 - val_acc: 0.9432\n",
      "Epoch 2/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1604 - acc: 0.9362 - val_loss: 0.1526 - val_acc: 0.9421\n",
      "Epoch 3/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1593 - acc: 0.9370 - val_loss: 0.1714 - val_acc: 0.9387\n",
      "Epoch 4/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1576 - acc: 0.9385 - val_loss: 0.1520 - val_acc: 0.9357\n",
      "Epoch 5/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1598 - acc: 0.9378 - val_loss: 0.1421 - val_acc: 0.9434\n",
      "Epoch 6/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1574 - acc: 0.9383 - val_loss: 0.1451 - val_acc: 0.9434\n",
      "Epoch 7/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1592 - acc: 0.9383 - val_loss: 0.1404 - val_acc: 0.9436\n",
      "Epoch 8/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1553 - acc: 0.9392 - val_loss: 0.1447 - val_acc: 0.9426\n",
      "Epoch 9/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1577 - acc: 0.9366 - val_loss: 0.1561 - val_acc: 0.9403\n",
      "Epoch 10/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1565 - acc: 0.9384 - val_loss: 0.1542 - val_acc: 0.9417\n",
      "Epoch 11/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1578 - acc: 0.9390 - val_loss: 0.1513 - val_acc: 0.9363\n",
      "Epoch 12/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1574 - acc: 0.9380 - val_loss: 0.1746 - val_acc: 0.9349\n",
      "Epoch 13/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1569 - acc: 0.9371 - val_loss: 0.1530 - val_acc: 0.9396\n",
      "Epoch 14/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1573 - acc: 0.9384 - val_loss: 0.1415 - val_acc: 0.9432\n",
      "Epoch 15/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1557 - acc: 0.9378 - val_loss: 0.1562 - val_acc: 0.9382\n",
      "Epoch 16/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1568 - acc: 0.9391 - val_loss: 0.1568 - val_acc: 0.9400\n",
      "Epoch 17/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1547 - acc: 0.9382 - val_loss: 0.1603 - val_acc: 0.9376\n",
      "Epoch 18/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1562 - acc: 0.9390 - val_loss: 0.1577 - val_acc: 0.9395\n",
      "Epoch 19/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1554 - acc: 0.9378 - val_loss: 0.1529 - val_acc: 0.9394\n",
      "Epoch 20/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1555 - acc: 0.9381 - val_loss: 0.1460 - val_acc: 0.9441\n",
      "(7618, 2)\n",
      "  auc =  0.9889102274764033\n",
      "(200000,)\n",
      "Fold 1\n",
      "Train on 30470 samples, validate on 7618 samples\n",
      "Epoch 1/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1525 - acc: 0.9406 - val_loss: 0.1491 - val_acc: 0.9411\n",
      "Epoch 2/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1514 - acc: 0.9403 - val_loss: 0.1673 - val_acc: 0.9336\n",
      "Epoch 3/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1535 - acc: 0.9392 - val_loss: 0.1504 - val_acc: 0.9400\n",
      "Epoch 4/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1531 - acc: 0.9403 - val_loss: 0.1438 - val_acc: 0.9395\n",
      "Epoch 5/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1502 - acc: 0.9412 - val_loss: 0.1437 - val_acc: 0.9412\n",
      "Epoch 6/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1526 - acc: 0.9398 - val_loss: 0.1821 - val_acc: 0.9278\n",
      "Epoch 7/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1531 - acc: 0.9401 - val_loss: 0.1651 - val_acc: 0.9392\n",
      "Epoch 8/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1525 - acc: 0.9398 - val_loss: 0.1525 - val_acc: 0.9399\n",
      "Epoch 9/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1545 - acc: 0.9394 - val_loss: 0.1453 - val_acc: 0.9411\n",
      "Epoch 10/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1546 - acc: 0.9403 - val_loss: 0.1479 - val_acc: 0.9412\n",
      "Epoch 11/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1514 - acc: 0.9406 - val_loss: 0.1459 - val_acc: 0.9399\n",
      "Epoch 12/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1513 - acc: 0.9405 - val_loss: 0.1539 - val_acc: 0.9399\n",
      "Epoch 13/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1522 - acc: 0.9399 - val_loss: 0.1458 - val_acc: 0.9411\n",
      "Epoch 14/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1514 - acc: 0.9412 - val_loss: 0.1529 - val_acc: 0.9386\n",
      "Epoch 15/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1499 - acc: 0.9403 - val_loss: 0.1440 - val_acc: 0.9395\n",
      "Epoch 16/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1523 - acc: 0.9397 - val_loss: 0.1524 - val_acc: 0.9409\n",
      "Epoch 17/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1525 - acc: 0.9404 - val_loss: 0.1487 - val_acc: 0.9411\n",
      "Epoch 18/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1523 - acc: 0.9400 - val_loss: 0.1675 - val_acc: 0.9341\n",
      "Epoch 19/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1512 - acc: 0.9392 - val_loss: 0.1897 - val_acc: 0.9307\n",
      "Epoch 20/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1506 - acc: 0.9407 - val_loss: 0.1692 - val_acc: 0.9289\n",
      "(7618, 2)\n",
      "  auc =  0.9877961257559629\n",
      "(200000,)\n",
      "Fold 2\n",
      "Train on 30470 samples, validate on 7618 samples\n",
      "Epoch 1/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1518 - acc: 0.9393 - val_loss: 0.1582 - val_acc: 0.9439\n",
      "Epoch 2/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1523 - acc: 0.9390 - val_loss: 0.1497 - val_acc: 0.9454\n",
      "Epoch 3/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1522 - acc: 0.9393 - val_loss: 0.1556 - val_acc: 0.9422\n",
      "Epoch 4/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1511 - acc: 0.9403 - val_loss: 0.1552 - val_acc: 0.9415\n",
      "Epoch 5/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1534 - acc: 0.9391 - val_loss: 0.1590 - val_acc: 0.9376\n",
      "Epoch 6/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1531 - acc: 0.9380 - val_loss: 0.1634 - val_acc: 0.9371\n",
      "Epoch 7/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1521 - acc: 0.9392 - val_loss: 0.1447 - val_acc: 0.9454\n",
      "Epoch 8/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1522 - acc: 0.9388 - val_loss: 0.1485 - val_acc: 0.9446\n",
      "Epoch 9/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1495 - acc: 0.9411 - val_loss: 0.1517 - val_acc: 0.9426\n",
      "Epoch 10/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1518 - acc: 0.9395 - val_loss: 0.1494 - val_acc: 0.9460\n",
      "Epoch 11/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1518 - acc: 0.9395 - val_loss: 0.1578 - val_acc: 0.9426\n",
      "Epoch 12/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1532 - acc: 0.9394 - val_loss: 0.1455 - val_acc: 0.9457\n",
      "Epoch 13/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1517 - acc: 0.9393 - val_loss: 0.1654 - val_acc: 0.9382\n",
      "Epoch 14/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1508 - acc: 0.9402 - val_loss: 0.1477 - val_acc: 0.9459\n",
      "Epoch 15/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1520 - acc: 0.9407 - val_loss: 0.1605 - val_acc: 0.9392\n",
      "Epoch 16/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1508 - acc: 0.9402 - val_loss: 0.1744 - val_acc: 0.9313\n",
      "Epoch 17/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1512 - acc: 0.9412 - val_loss: 0.1486 - val_acc: 0.9412\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1520 - acc: 0.9399 - val_loss: 0.1546 - val_acc: 0.9418\n",
      "Epoch 19/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1511 - acc: 0.9401 - val_loss: 0.1496 - val_acc: 0.9418\n",
      "Epoch 20/20\n",
      "30470/30470 [==============================] - 0s 12us/step - loss: 0.1509 - acc: 0.9394 - val_loss: 0.1460 - val_acc: 0.9455\n",
      "(7618, 2)\n",
      "  auc =  0.9880971899872156\n",
      "(200000,)\n",
      "Fold 3\n",
      "Train on 30471 samples, validate on 7617 samples\n",
      "Epoch 1/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1512 - acc: 0.9397 - val_loss: 0.1548 - val_acc: 0.9350\n",
      "Epoch 2/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1509 - acc: 0.9401 - val_loss: 0.1394 - val_acc: 0.9460\n",
      "Epoch 3/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1513 - acc: 0.9392 - val_loss: 0.1590 - val_acc: 0.9312\n",
      "Epoch 4/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1521 - acc: 0.9384 - val_loss: 0.1368 - val_acc: 0.9477\n",
      "Epoch 5/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1506 - acc: 0.9414 - val_loss: 0.1401 - val_acc: 0.9442\n",
      "Epoch 6/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1518 - acc: 0.9408 - val_loss: 0.1648 - val_acc: 0.9344\n",
      "Epoch 7/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1512 - acc: 0.9407 - val_loss: 0.1436 - val_acc: 0.9417\n",
      "Epoch 8/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1522 - acc: 0.9381 - val_loss: 0.1407 - val_acc: 0.9425\n",
      "Epoch 9/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1513 - acc: 0.9397 - val_loss: 0.1439 - val_acc: 0.9451\n",
      "Epoch 10/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1517 - acc: 0.9400 - val_loss: 0.1363 - val_acc: 0.9460\n",
      "Epoch 11/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1506 - acc: 0.9400 - val_loss: 0.1643 - val_acc: 0.9312\n",
      "Epoch 12/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1513 - acc: 0.9402 - val_loss: 0.1362 - val_acc: 0.9474\n",
      "Epoch 13/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1476 - acc: 0.9407 - val_loss: 0.1410 - val_acc: 0.9435\n",
      "Epoch 14/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1497 - acc: 0.9405 - val_loss: 0.1336 - val_acc: 0.9477\n",
      "Epoch 15/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1497 - acc: 0.9408 - val_loss: 0.1363 - val_acc: 0.9463\n",
      "Epoch 16/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1510 - acc: 0.9401 - val_loss: 0.1350 - val_acc: 0.9480\n",
      "Epoch 17/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1503 - acc: 0.9402 - val_loss: 0.1470 - val_acc: 0.9388\n",
      "Epoch 18/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1509 - acc: 0.9416 - val_loss: 0.1403 - val_acc: 0.9443\n",
      "Epoch 19/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1495 - acc: 0.9395 - val_loss: 0.1372 - val_acc: 0.9446\n",
      "Epoch 20/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1487 - acc: 0.9410 - val_loss: 0.1403 - val_acc: 0.9463\n",
      "(7617, 2)\n",
      "  auc =  0.9889390429930971\n",
      "(200000,)\n",
      "Fold 4\n",
      "Train on 30471 samples, validate on 7617 samples\n",
      "Epoch 1/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1468 - acc: 0.9416 - val_loss: 0.1544 - val_acc: 0.9400\n",
      "Epoch 2/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1470 - acc: 0.9410 - val_loss: 0.1561 - val_acc: 0.9341\n",
      "Epoch 3/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1477 - acc: 0.9404 - val_loss: 0.1563 - val_acc: 0.9382\n",
      "Epoch 4/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1468 - acc: 0.9421 - val_loss: 0.1546 - val_acc: 0.9376\n",
      "Epoch 5/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1480 - acc: 0.9418 - val_loss: 0.1468 - val_acc: 0.9424\n",
      "Epoch 6/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1472 - acc: 0.9419 - val_loss: 0.1466 - val_acc: 0.9405\n",
      "Epoch 7/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1462 - acc: 0.9423 - val_loss: 0.1469 - val_acc: 0.9425\n",
      "Epoch 8/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1473 - acc: 0.9417 - val_loss: 0.1459 - val_acc: 0.9441\n",
      "Epoch 9/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1477 - acc: 0.9417 - val_loss: 0.1448 - val_acc: 0.9442\n",
      "Epoch 10/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1485 - acc: 0.9405 - val_loss: 0.1477 - val_acc: 0.9426\n",
      "Epoch 11/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1475 - acc: 0.9423 - val_loss: 0.1481 - val_acc: 0.9426\n",
      "Epoch 12/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1465 - acc: 0.9412 - val_loss: 0.1549 - val_acc: 0.9369\n",
      "Epoch 13/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1471 - acc: 0.9416 - val_loss: 0.1551 - val_acc: 0.9378\n",
      "Epoch 14/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1466 - acc: 0.9423 - val_loss: 0.1487 - val_acc: 0.9420\n",
      "Epoch 15/20\n",
      "30471/30471 [==============================] - 0s 13us/step - loss: 0.1469 - acc: 0.9417 - val_loss: 0.1455 - val_acc: 0.9428\n",
      "Epoch 16/20\n",
      "30471/30471 [==============================] - 0s 14us/step - loss: 0.1466 - acc: 0.9422 - val_loss: 0.1668 - val_acc: 0.9304\n",
      "Epoch 17/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1451 - acc: 0.9432 - val_loss: 0.1517 - val_acc: 0.9409\n",
      "Epoch 18/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1468 - acc: 0.9415 - val_loss: 0.1637 - val_acc: 0.9354\n",
      "Epoch 19/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1472 - acc: 0.9414 - val_loss: 0.1525 - val_acc: 0.9404\n",
      "Epoch 20/20\n",
      "30471/30471 [==============================] - 0s 12us/step - loss: 0.1481 - acc: 0.9417 - val_loss: 0.1448 - val_acc: 0.9421\n",
      "(7617, 2)\n",
      "  auc =  0.9873906038226428\n",
      "(200000,)\n"
     ]
    }
   ],
   "source": [
    "#Load previous data\n",
    "\n",
    "catb_df = pd.read_csv(\"../input/catboost_output.csv\")\n",
    "lgbm_df = pd.read_csv(\"../input/lgbm_output.csv\")\n",
    "nn_df = pd.read_csv(\"../input/full_nn_output.csv\")\n",
    "\n",
    "submission_catb_df = pd.read_csv(\"submission_catboost.csv\")\n",
    "submission_lgbm_df = pd.read_csv(\"submission_lgbm.csv\")\n",
    "submission_full_nn_df = pd.read_csv(\"submission_full_nn.csv\")\n",
    "\n",
    "combined_df = pd.DataFrame({\"ID_code\": catb_df.ID_code.values})\n",
    "combined_df['cat_out'] = catb_df['output']\n",
    "combined_df['lgbm_out'] = lgbm_df['output']\n",
    "combined_df['full_nn_out'] = nn_df['output']\n",
    "combined_df['target1'] = train_df['target']\n",
    "combined_df['target0'] = 1 - train_df['target']\n",
    "\n",
    "#drop 90% of 0 scores to make balanced input for NN\n",
    "#combined_df = combined_df.drop(combined_df[combined_df['target0'] > 0.9].sample(frac=0.1).index)\n",
    "zero_subset_df = combined_df[combined_df['target0'] > 0.9].sample(frac = 0.1)\n",
    "ones_subset_df = combined_df[combined_df['target1'] > 0.9]\n",
    "\n",
    "frames = [zero_subset_df, ones_subset_df]\n",
    "\n",
    "combined_df = pd.concat(frames)\n",
    "combined_df = shuffle(combined_df)\n",
    "\n",
    "combined_test_df = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "combined_test_df['cat_out'] = submission_catb_df['target']\n",
    "combined_test_df['lgbm_out'] = submission_lgbm_df['target']\n",
    "combined_test_df['full_nn_out'] = submission_full_nn_df['target']\n",
    "\n",
    "zero_subset_df.to_csv('../input/zeros_sample.csv')\n",
    "ones_subset_df.to_csv('../input/ones_sample.csv')\n",
    "combined_df.to_csv('../input/combined.csv')\n",
    "\n",
    "#idx = [c for c in combined_df.columns if c not in ['ID_code', 'target']]\n",
    "features = [c for c in combined_df.columns if c not in ['ID_code', 'target', 'target1', 'target0']]\n",
    "target = combined_df.loc[:, ['target1', 'target0']]\n",
    "\n",
    "y_test_pred = np.zeros(len(test_df))\n",
    "    \n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(combined_df)):\n",
    "    print(\"Fold {}\".format(idx))\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    X_train, X_valid = combined_df[features].iloc[train_index,:], combined_df[features].iloc[valid_index,:]\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size = 512, validation_data =(X_valid, y_valid))\n",
    "    pred = model.predict_proba(X_valid)\n",
    "    print(pred.shape)\n",
    "    print( \"  auc = \", roc_auc_score(y_valid, pred) )\n",
    "    y_test_pred += model.predict_proba(combined_test_df[features])[:,0]\n",
    "    print(y_test_pred.shape)\n",
    "\n",
    "#save base submission\n",
    "sub_df1 = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\n",
    "sub_df1[\"target\"] = y_test_pred / N_FOLDS\n",
    "sub_df1.to_csv(\"submission_nn.csv\", index=False)\n",
    "#make combined data set for comparison\n",
    "combined_test_df['nn_out'] = y_test_pred / N_FOLDS\n",
    "combined_test_df.to_csv(\"../input/combined_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
